"# Section 2: High-Level Architecture\n\n- **Frontend**: Next.js web app (`apps/web/`) with shadcn/ui components. Build on existing pages (e.g., extend `apps/web/src/app/page.tsx` for dashboard, reuse chat UI from `apps/web/src/app/ai/page.tsx` for RAG queries).\n- **Backend**: tRPC server (`apps/server/`) with Hono. Use existing routers (`apps/server/src/routers/index.ts`) to add endpoints for search and ingestion.\n- **Database**: Supabase (local dev via `apps/server/supabase/config.toml`) with pgvector extension for embeddings. Use Drizzle ORM for schemas/migrations.\n- **Data Ingestion**: FireCrawl MCP to scrape websites (e.g., LinkedIn, Twitter, news sites) and extract lead info.\n- **RAG/Search**: Mem-0 Graph RAG for querying leads (store graph in Supabase vectors; query via natural language).\n- **Deployment**: Coolify on Hostinger VPS to host the web app, server, and Supabase instance.\n- **Integrations**:\n  - Use Vercel AI SDK (already in `package.json`) for any AI-assisted extraction during crawling.\n  - Follow rules: Always use Supabase MCP tools for DB ops; review code structure before/after changes.\n\nData Flow:\n1. Admin triggers crawl → FireCrawl scrapes data → Extract embeddings → Store in Supabase.\n2. User searches on dashboard → tRPC queries RAG → Display results." 